{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Artificial Neural Network (ANN) - Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/NN_FF_Completo.svg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the illustration, a neural network with 3 layers can be seen, where each layer has a fixed number of neurons. The first layer is the input layer, where data is provided to the network, followed by the hidden layer, responsible for sequential calculations along the network, and finally the output layer, with the possible solution of the model.\n",
    "A neuron in this network is treated as a basic processing unit, and each neuron differs through the activation function it represents. This activation function, as we will see, is responsible for receiving information from the input layer and transforming it through the layers until the output.\n",
    "\n",
    "The input has $n_0$ neurons, $(x_1,...,x_{n_{0}})$, and an additional neuron $x_0$ that specifies one of the parameters of the network, called bias. The hidden layer has $n_1$ neurons, $z_1,...,z_{n_{1}}$, and an additional neuron $z_0$ that specifies the bias for the output neurons. And finally, the output layer has $n_2$ neurons, $O_1,...,O_{n_{2}}$. The neuron that specifies the bias has no incoming edge (arrow that connects one neuron to another), as its value is fixed at $1$.\n",
    "\n",
    "The parameters that make up a network are the bias $(b)$ and the synaptic weight $(\\omega)$ (I will simply refer to it as weight). They are the parameters by which the network is said to learn. The weight $\\omega$ has the role of controlling the signal sent between two neurons. It decides how much influence an input will have on the output of the neuron. The bias is a constant that ensures that even if all inputs have a null value, the neuron is still capable of applying an activation function to generate the output.\n",
    "\n",
    "Before discussing a little more about the parameters of a network, consider the possible activation functions that can be adopted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation functions**:\n",
    "\n",
    "Note that in the first layer, we will not have any activation function, which can be interpreted as a neuron that has the identity function as its activation function. For the other layers, a function will be chosen. In a generic way, we write the j-th and k-th neuron of the hidden and output layer as:\n",
    "\n",
    "$$z_j^{(1)}=\\sigma^{(1)}( . ),$$\n",
    "$$O_k=\\sigma^{(2)}( . ).$$\n",
    "\n",
    "The functions $\\sigma^{(1)}(.)$ and $\\sigma^{(2)}(.)$ can be chosen from one of the following activation functions listed below.\n",
    "\n",
    "1. **Identity**\n",
    "\n",
    "Returns its own argument.\n",
    "$$\\sigma(x) = x$$\n",
    "\n",
    "2. **Step**\n",
    "\n",
    "A binary function, where the neuron has an output of 0 or 1.\n",
    "\n",
    "$$\\sigma(x): \\left\\{ \\begin{array}{ll} \n",
    "0 \\textrm{ se } x\\leq 0\\\\\n",
    "1 \\textrm{ se } x> 0\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "**3. ReLU**\n",
    "\n",
    "The neuron remains inactive if the input $x$ is less than or equal to zero, or grows linearly otherwise.\n",
    "$$\\sigma(x): \\left\\{ \\begin{array}{ll} \n",
    "0 \\textrm{ se } x\\leq 0\\\\\n",
    "x \\textrm{ se } x> 0\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "**4. Sigmoid**\n",
    "\n",
    "The function maps the input $x$ in the value between $[0,1]$.\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}, ~~~~ \\sigma: \\mathbb{R} \\to [0,1]$$ \n",
    "\n",
    "**5. hyperbolic tangent (tanh)**\n",
    "\n",
    "The function maps the input $x$ in the value between $[-1,1]$.\n",
    "\n",
    "$$\\sigma(x) = \\frac{e^x - e^{-x}}{e^x - e^{-x}} = \\frac{e^{2x}-1}{e^{2x} +1}, ~~~~ \\sigma: \\mathbb{R} \\to [-1,1]$$\n",
    "\n",
    "**6. Softmax**\n",
    "\n",
    "It is a generalization of the sigmoid (Logistic) function for multiple dimensions. It is usually used in the output layer, and unlike other functions, softmax depends not only on the input provided to the k-th neuron, but also on all neurons in that layer. Its purpose is to normalize the output of the network into a probability distribution over the predicted classes.\n",
    "\n",
    "$$\\sigma(x_k|\\vec{x}) = \\frac{e^{x_k}}{\\sum^{d}_i= e^{x_i}}, ~~~~ \\sigma: \\mathbb{R}^d \\to (0,1)^d$$\n",
    "\n",
    "Sendo $x=(x_1, ..., x_d)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 FeedFoward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"Images/NN_FF_Simplificado.svg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following illustration with the respective network parameters between each layer. Suppose we have the following database with $n$ points and $n_0$ attributes represented in matrix form:\n",
    "\n",
    "$$\\mathbf{D} =\n",
    "\\left( \\begin{array}{c|ccc|c}\n",
    "~    &X_{1}&\\cdots & X_{n_0}  & Y\\\\\n",
    "\\hline\n",
    "x_{1} & x_{11}& \\cdots&x_{1n_0}&y_1 \\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\n",
    "x_{n}&x_{n1}&\\cdots&x_{nn_0}&y_n\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "Each point $x_j = (x_{j1},\\cdots,x_{jn_0})$ is in a $n_0$-dimensional space, requiring $n_0$ neurons in the input layer to receive a point from this database $\\mathbf{D}$. $X_1,...,X_{n_0}$ are the labels of the independent attributes, which give the dimension of the space $\\mathbb{R}^{n_{0}}$, and $Y=(y_1,...,y_n)$ the label for the dependent attribute.\n",
    "\n",
    "Here, we will make a brief comparison to linear regression to verify how linear regression is a particular case of neural networks.\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "In linear regression, we have a set of points from our database $\\mathbf{D}$, and we believe that there is a linear correlation of the independent attributes $X_1,...,X_{n_0}$ with the dependent variable $Y$ as follows:\n",
    "\n",
    "$$\\hat{y}_j = f(x_j) = b_j+ \\sum_{i=1}^{n_0}\\omega_{ij}x_{ji}$$ \n",
    "\n",
    "where $x_j = (x_{j1}, x_{j2},\\cdots,x_{in_0})$ is a point in the domain (value of each independent attribute), $y_j$ is a point in the image (value of the dependent variable) that correlates $x_i$ with the other points in the space $\\mathbb{R}^{n_{0}}$, and $\\hat{y}_j$ is the model's prediction for the function that best approximates $y_j$. In each round, a new point $x_i$ from the database $\\mathbf{D}$ is provided, and a point $\\hat{y}j$ is generated and compared to $y_j$. The model is thus trained to find the parameters $\\omega{ij}$ and $b_j$ that best approximate $\\hat{Y}=(\\hat{y}_1,...,\\hat{y}_n)$ to the image points $Y = (y_1,...,y_n)$. At the end, we have a function $\\hat{y}j=f(x_j)$ capable of predicting the value of any new point $x_j$ knowing $\\omega{ij}$ and $b_j$.\n",
    "\n",
    "**Neural Network**\n",
    "\n",
    "In the neural network, $x_j = (x_{j1}, x_{j2},\\cdots,x_{jn_0})$ is also the input of the model, where each neuron receives an attribute. For example, the first neuron $x_1$ receives $x_{i1}$, the second neuron $x_2$ receives $x_{i2}$, and so on until reaching the $n_0$-th neuron. Like in linear regression, a linear correlation will be generated between the neurons multiplied by the weights $\\omega_{ij}$ and added to the bias $b_j$.\n",
    "\n",
    "$$\\textrm{net}_j = b_j+ \\sum_{i=1}^{n_0}\\omega_{ij}x_i$$\n",
    "\n",
    "\n",
    "This is the information that will arrive at the $j$-th neuron of the hidden layer $z_j^{(1)}$. The same will happen for all neurons in the hidden layer, which will receive this linear correlation of neurons from the input. Therefore, if we consider that $z_j^{(1)}$ is the neuron of the output layer, with the identity activation function, we fall into the case of a linear regression.\n",
    "\n",
    "Now let's consider that we have generic activation functions in the hidden and output layers:\n",
    "\n",
    "$$z_j^{(1)}=\\sigma^{(1)}( . )~,$$ \n",
    "$$O_k=\\sigma^{(2)}( . )~.$$\n",
    "\n",
    "The feedfoward process is the following:\n",
    "$$\n",
    "\\textrm{(I)} : \\left\\{ \\begin{array}{ll} \n",
    "\\textrm{net}_j = b_j+ \\sum_{i=1}^{n_0}\\omega_{ij}x_i\\\\\n",
    "\\\\ \\textcolor{red}{z_j^{(1)}=\\sigma^{(1)}(\\textrm{net}_j)}\n",
    "\\end{array}\\right.\n",
    "\\textrm{(II)} : \\left\\{ \\begin{array}{ll} \n",
    "\\textrm{net}_k = b_k^{(1)}+ \\sum_{j=1}^{n_1}\\omega^{(1)}_{jk}z_j^{(1)}\\\\\n",
    "\\\\\\textcolor{green}{O_k=\\sigma^{(2)}(\\textrm{net}_k)}\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "It is worth noting that this is the process responsible for composing activation functions. Let's write the output neurons by explicitly indicating their dependence on the network parameters:\n",
    "\n",
    "$$\\textcolor{green}{O_k=\\sigma^{(2)}(\\textrm{net}_k(\\omega_{jk},b_k,} ~\\textcolor{red}{z_j^{(1)}}~\\textcolor{green}{))}$$\n",
    "$$\\textcolor{green}{O_k=\\sigma^{(2)}(\\textrm{net}_k(\\omega^{(1)}_{jk},b^{(1)}_k,} ~\\textcolor{red}{\\sigma^{(1)}(\\textrm{net}_j(\\omega_{ij},b_j,x_i))}~\\textcolor{green}{))}$$\n",
    "\n",
    "Therefore, for each new layer of the network we will have a new activation function composed of the others, in such a way that the input $x_i$ is the most internal variable in this composition of functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Cost Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Classification**\n",
    "\n",
    "- **Cross-entropy:**\n",
    "\n",
    "Classification task for multiple classes $n_2$ where $y_i \\in {c_1,c_2,...,c_{n_2}}$. The number of neurons in the output layer will be equal to the number of classes. Additionally, each class is encoded using one-hot encoding, where class $c_i$ is encoded as a vector in the basis of an $n_2$-dimensional space, $e_i=(e_{i1},e_{i2},...,e_{in_2})$, with $e_{ii}=1$ and $e_{ij}=0$, $\\forall j\\neq i$. Therefore, given the input $x \\in \\mathbb{R}^{n_0}$, with $y=(y_1,...,y_{n_2})$, where $y \\in {e_1,...,e_{n_2}}$, the cross-entropy is given by:\n",
    "$$C_x = - \\sum_{k=1}^{n_2} y_{k} \\ln(O_k)$$\n",
    "\n",
    "- **Binary cross-entropy:**\n",
    "  \n",
    "Classification task with binary classes. Given the input $x \\in \\mathbb{R}^{n_0}$ and $y \\in {0,1}$, and having a single neuron $O \\in {0,1}$ in the output, the following cost function is used:\n",
    "$$C_x = - ( y \\ln(O)+(1-y)\\ln(O))$$\n",
    "\n",
    "**2. Regression**\n",
    "\n",
    "Mean Squared Error (MSE):\n",
    "Let $x \\in \\mathbb{R}^{n_0}$ be the input, the task here is to obtain the squared deviation between the predicted values in the output layer with $O \\in \\mathbb{R}^{n_2}$ and the correct value $y \\in \\mathbb{R}^{n_2}$.\n",
    "$$C_x = \\frac{1}{n_2} \\sum_{k=1}^{n_2} (y_k - O_k)^2$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Backpropagation and Gradient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent**\n",
    "\n",
    "Once the cost function $C_x$ to be used in the model has been established, we need to search for network parameters that minimize it. Gradient Descent is the method that will help us in the search for these parameters $(\\omega^{(l)}_{ij}, b^{(l)}_j)$ that minimize $C_x$. Here, I will consider the Mean Square Error function:\n",
    "\n",
    "$$C_x = \\frac{1}{n_2} \\sum_{k=1}^{n_2} (y_k - \\textcolor{green}{O_k})^2$$\n",
    "\n",
    "For a given input $(x,y)$ in the database, the network will compute the output $O$ through the Feedforward step, which as we have seen provides a composition of activation functions:\n",
    "\n",
    "$$\\textcolor{green}{O_k=\\sigma^{(2)}(\\textrm{net}k(\\omega^{(1)}{jk},b^{(1)}_k,} \\textcolor{red}{\\sigma^{(1)}(\\textrm{net}j(\\omega{ij},b_j,x_i))}\\textcolor{green}{))}$$\n",
    "\n",
    "Writing the cost function explicitly showing its dependencies, we have:\n",
    "\n",
    "$$C_x = C_x(\\textcolor{green}{O_k(\\textrm{net}k(\\omega^{(1)}{jk},b^{(1)}_k,} \\textcolor{red}{z^{(1)}_j(\\textrm{net}j(\\omega{ij},b_j,x_i)}\\textcolor{green}{))}).$$\n",
    "\n",
    "Here, I wrote the neuron label instead of the activation function, but both notations are equivalent. The idea will be to examine how an output neuron, $O_k$ for example, deviates from the corresponding value $y_k$ that we want to approximate given the network parameters $w$ and $b$. The greater the error, the greater the change in the parameters, and the smaller the error, the smaller the change. In addition, we also want neurons in the input and hidden layers to be updated through a function that is a function of the error calculated at the output.\n",
    "\n",
    "We can calculate a variation of the error function with respect to the network parameters through the partial derivatives $\\frac{\\partial C_x}{\\partial b^{(l)}j}$ and $\\frac{\\partial C_x}{\\partial \\omega^{(l)}{ij}}$. This variation can be viewed as a residual error to be subtracted from the parameters in order to find $w_{jk}$ and $b_k$ that minimize $C_x$. Once these partial derivatives have been calculated, we update the parameters using the gradient descent:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{ll} \n",
    "\\omega^{(l)}_{ij} = \\omega^{(l)}_{ij} - \\alpha\\nabla_{\\omega_{ij}}^{(l)} \\\\\n",
    "\\\\b^{(l)}_j = b^{(l)}_j - \\alpha \\nabla_{b_j}^{(l)} \n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "$$\\nabla_{b_j}^{(l)} = \\frac{\\partial C_x}{\\partial b^{(l)}_j} , ~~~~ \\nabla_{\\omega_{ij}}^{(l)}=\\frac{\\partial C_x}{\\partial \\omega^{(l)}_{ij}}$$\n",
    "\n",
    "where $\\alpha$ is a parameter that we control, called the learning rate. We will use the chain rule to calculate such partial derivatives in order to write them in terms of known derivatives. This is possible because all activation functions are differentiable and the cost function depends on all network parameters, as explained above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Images/NN_BP_Simplificado.svg'>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backpropagation step is used to learn the parameters of the network between each layer. This name is given by the way we propagate the error, starting from the output and reaching the input, through the gradient of the cost function in terms of the parameters. The gradient descent in this step has the role of updating these parameters.\n",
    "\n",
    "Consider again the cost function in terms of the parameters and network functions:\n",
    "\n",
    "$$ C_x = C_x(\\textcolor{green}{O_k(\\textrm{net}k(\\omega^{(1)}{jk},b^{(1)}_k,} \\textcolor{red}{z^{(1)}_j(\\textrm{net}j(\\omega{ij},b_j,x_i)}\\textcolor{green}{))})$$\n",
    "\n",
    "Let's take the partial derivatives in terms of the parameters $(b_k,\\omega_{jk})$ between the output and hidden layer, and $(b_j,\\omega_{ij})$ between the hidden and input layer:\n",
    "\n",
    "$$\n",
    "\\textrm{(II)} : \\left\\{ \\begin{array}{ll} \n",
    "\\nabla_{\\omega_{jk}}^{(1)} =\\frac{\\partial C_x}{\\partial \\omega^{(1)}_{jk}}= \\textcolor{green}{\\frac{\\partial C_x}{\\partial{net_k} }}\\textcolor{red}{\\frac{\\partial{net_k}}{\\partial {\\omega^{(1)}_{jk}}}}=\\textcolor{green}{\\delta^{(2)}_k} \\textcolor{red}{z_{j}^{(1)}}\\\\\n",
    "\\\\\\nabla_{b_k}^{(1)} =\\frac{\\partial C_x}{\\partial b^{(1)}_{k}} =\\textcolor{green}{\\frac{\\partial C_x}{\\partial{net_k}}}\\frac{\\partial{net_k}}{\\partial {b^{(1)}_{k}}}=\\textcolor{green}{\\delta^{(2)}_k}\\\\\n",
    "\\end{array}\\right. ~~ \\longrightarrow ~~\n",
    "\\textrm{(I)} : \\left\\{ \\begin{array}{ll} \n",
    "\\nabla_{\\omega_{ij}} =\\frac{\\partial C_x}{\\partial \\omega_{ij}}= \\textcolor{green}{\\frac{\\partial C_x}{\\partial{net_j} }}\\textcolor{red}{\\frac{\\partial{net_j}}{\\partial {\\omega_{ij}}}}=\\textcolor{green}{\\delta^{(1)}_j} \\textcolor{red}{x_i}\\\\\n",
    "\\\\\\nabla_{b_j} =\\frac{\\partial C_x}{\\partial b_{j}} =\\textcolor{green}{\\frac{\\partial C_x}{\\partial{net_j}}}\\frac{\\partial{net_j}}{\\partial {b_{j}}}=\\textcolor{green}{\\delta^{(1)}_j}\\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "Here, the chain rule was applied to write the partial derivative of the cost function in terms of the parameters as a product of partial derivatives. This is done in both steps $(II)$ and $(I)$. The partial derivatives that I referred to as $\\delta^{(2)}_k$ and $\\delta^{(1)}_j$ are called local gradients and can be interpreted as an error associated with each neuron individually. This idea is illustrated in the above image, where $\\delta^{(2)}_k$ is the error associated with the neuron $O_k$ in the output layer and $\\delta^{(1)}_j$ is the error of the $j$-th neuron $z_j^{(1)}$ in the hidden layer. Through the chain rule, we are able to calculate these individual errors as follows:\n",
    "\n",
    "$$\\textcolor{green}{\\delta^{(2)}_k =\\frac{\\partial C_x}{\\partial \\text{net}_k}} = \\frac{\\partial C_x}{\\partial O_k}\\frac{\\partial O_k}{\\partial{net_k}}~~\\longrightarrow~~\\delta^{(1)}_j=\\frac{\\partial C_x}{\\partial{net_j}}= \\sum_{k=1}^{n_2}\\textcolor{green}{\\frac{\\partial C_x}{\\partial{net_k}}}\\frac{\\partial net_k}{\\partial{z_j^{(1)}}}\\frac{\\partial z_j^{(1)}}{\\partial{ net_j}}\\\\\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\delta^{(1)}_j=\\frac{\\partial z_j^{(1)}}{\\partial{ net_j}} \\sum_{k=1}^{n_2}\\textcolor{green}{\\delta^{(2)}_k}\\omega_{jk}$$\n",
    "\n",
    "Note how the individual neuron errors in the hidden layer have a dependence on the errors of the neurons in the output layer, giving the idea of propagating the error in the opposite direction of the Feedforward process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update with Gradient descent**\n",
    "\n",
    "$$\n",
    "\\textrm{Atualização (II) : }\\left\\{ \\begin{array}{ll} \n",
    "\\omega^{(1)}_{jk} = \\omega^{(1)}_{jk} - \\alpha\\textcolor{green}{\\delta^{(2)}_k} \\textcolor{red}{z_{j}^{(1)}}\\\\\n",
    "\\\\b^{(1)}_k = b^{(1)}_k - \\alpha \\textcolor{green}{\\delta^{(2)}_k} \n",
    "\\end{array}\\right.\n",
    "\\textrm{Atualização (I) : }\\left\\{ \\begin{array}{ll} \n",
    "\\omega_{ij} = \\omega_{ij} - \\alpha\\textcolor{green}{\\delta^{(1)}_j} \\textcolor{red}{x_i}\\\\\n",
    "\\\\b_j = b_j - \\alpha \\textcolor{green}{\\delta^{(1)}_j} \n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "After defining the value of $\\alpha$ and calculating the partial derivatives, we can finally update the parameters and restart the process until we reach satisfactory parameters that minimize the chosen cost function as much as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Matrix representaion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will adopt a more compact representation that specifies only the topology of the network instead of the details of each individual neuron. To do this, we will use matrix notation instead of index notation. Consider the following illustration for the feedforward step:\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Images/NN_FF_Matricial.svg'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this illustration of the network, I considered only one input layer and one hidden layer. $\\vec{z}$ is a state vector that represents the hidden layer, it is composed of the neurons in that layer. Let's adopt a generic activation function $z_i = \\sigma ( . )$.\n",
    "\n",
    "$$\\vec{z} =\n",
    "\\left( \\begin{array}{c}\n",
    "z_{1}\\\\\n",
    "z_{2}\\\\\n",
    "z_{3}\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "The individual states of each neuron form a system of equations:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{ll} \n",
    "z_1 = \\sigma(x_{1}\\omega_{11} + x_{2}\\omega_{21} + x_{3}\\omega_{31} + b_1) \\\\\n",
    "z_2 =\\sigma(x_{1}\\omega_{12} + x_{2}\\omega_{22} + x_{3}\\omega_{32}  + b_2)\\\\\n",
    "z_3 = \\sigma(x_{1}\\omega_{13} + x_{2}\\omega_{23} + x_{3}\\omega_{33} + b_3) \n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "This system can be written in its matrix form. For that, we must consider an input vector $\\vec{x}$ and a vector for the biases $b_i$:\n",
    "\n",
    "$$\\vec{x} =\n",
    "\\left( \\begin{array}{c}\n",
    "x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "x_{3}\n",
    "\\end{array} \\right),~~~~\n",
    "\\vec{b} =\n",
    "\\left( \\begin{array}{c}\n",
    "b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "b_{3}\n",
    "\\end{array} \\right),\n",
    "$$\n",
    "\n",
    "as well as a matrix involving all synaptic weights $\\omega_{ij}$:\n",
    "\n",
    "$$\\vec{W} =\n",
    "\\left( \\begin{array}{ccc}\n",
    "\\omega_{11}&\\omega_{12} &\\omega_{13}\\\\\n",
    "\\omega_{21}&\\omega_{22} &\\omega_{23}\\\\\n",
    "\\omega_{31}&\\omega_{32} &\\omega_{33}\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "With this, we can rewrite the system of equations as follows:\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{c}\n",
    "z_{1}\\\\\n",
    "z_{2}\\\\\n",
    "z_{3}\n",
    "\\end{array} \\right)= \\sigma\\left(~~\n",
    "\\left( \\begin{array}{ccc}\n",
    "\\omega_{11}&\\omega_{21} &\\omega_{31}\\\\\n",
    "\\omega_{12}&\\omega_{22} &\\omega_{32}\\\\\n",
    "\\omega_{13}&\\omega_{23} &\\omega_{33}\n",
    "\\end{array} \\right)\n",
    "\\left( \\begin{array}{c}\n",
    "x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "x_{3}\n",
    "\\end{array} \\right)+\n",
    "\\left( \\begin{array}{c}\n",
    "b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "b_{3}\n",
    "\\end{array} \\right)\n",
    "~~\\right).\n",
    "$$\n",
    "\n",
    "Note that here the matrix involving the weights is transposed. The compact form is then:\n",
    "\n",
    "$$\\vec{z} = \\sigma(W^{T}\\vec{x}+\\vec{b})$$\n",
    "\n",
    "This matrix form allows us to represent the diagram of a network in a more compact way, focusing only on the layer instead of each neuron. This new representation is illustrated below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/NN_FF_NovaRepresentacao.svg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's represent the three-layer network studied earlier using its compact form. The backpropagation step will be illustrated when we address the representation of a network with multiple hidden layers. In the end, the feedforward step of the network is represented as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NN_FF_CompletoMatriz.svg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Multiple Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a network composed of a total of $l=h+1$ layers, with $h-1$ being the number of hidden layers. Let's adopt a generic activation function $z_i = \\sigma(.)$ for each neuron in the hidden layer and the identity function for neurons in the output layer. The representation of this network is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feedfoward**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"Images/NN_FF_MultiCamadas.svg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write the entire feedforward step in a compact form, in a single matrix equation, let us consider $\\vec{z}^{(0)} = \\vec{x}$ and $\\vec{z}^{(h+1)} = \\vec{O}$. Thus:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{ll} \n",
    "\\vec{\\textrm{Net}}^{(l)} = {W^{(l)}}^{T}\\vec{z}^{(l)} + \\vec{b}^{(l)}\\\\\n",
    "\\vec{z}^{(l+1)} = \\sigma^{(l+1)} \\left(\\vec{\\textrm{Net}}^{(l)}\\right),\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\vec{\\textrm{Net}}^{(l)}=\n",
    "\\left( \\begin{array}{c}\n",
    "{\\textrm{net}_1}^{(l)}\\\\\n",
    "{\\textrm{net}_2}^{(l)}\\\\\n",
    "\\vdots\\\\\n",
    "{\\textrm{net}_{h}}^{(l)}\n",
    "\\end{array} \\right),~~~~\n",
    "\\vec{z}^{(l)} =\n",
    "\\left( \\begin{array}{c}\n",
    "z_{1}^{(l)}\\\\\n",
    "z_{2}^{(l)}\\\\\n",
    "\\vdots\\\\\n",
    "z_{n_l}^{(l)}\n",
    "\\end{array} \\right),~~~~\n",
    "\\vec{b}^{(l)} =\n",
    "\\left( \\begin{array}{c}\n",
    "b_{1}^{(l)}\\\\\n",
    "b_{2}^{(l)}\\\\\n",
    "\\vdots\\\\\n",
    "b_{n_l}^{(l)}\n",
    "\\end{array} \\right).\n",
    "$$\n",
    "And the matrix involving the synaptic weights $\\omega_{ij}^{(l)}$:\n",
    "$$W^{(l)} =\n",
    "\\left( \\begin{array}{cccc}\n",
    "\\omega_{11}^{(l)}&\\omega_{12}^{(l)}&\\cdots &\\omega_{1n_{(l+1)}}^{(l)}\\\\\n",
    "\\omega_{21}^{(l)}&\\omega_{22}^{(l)}&\\cdots &\\omega_{2n_{(l+1)}}^{(l)}\\\\\n",
    "\\vdots     &\\vdots     &\\ddots & \\vdots\\\\\n",
    "\\omega_{n_{l}1}^{(l)}&\\omega_{n_{l}2}^{(l)}& \\cdots &\\omega_{n_{l} n_{(l+1)}}^{(l)}\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "The weight matrix is not necessarily square, since the number of neurons between one layer and another can differ, as frequently occurs between the hidden layer and the output layer. Remember that, in a generic way, $\\omega_{ij}^{(l)}$ is the synaptic weight referring to the $i$-th neuron of layer $l$ that connects to the $j$-th neuron of layer $l+1$. Therefore, the element $\\omega_{n_{l} n_{(l+1)}}^{(l)}$ refers to the synaptic weight of the last neuron of layer $l$ that connects to the last neuron of layer $l+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Images/NN_BP_MultiCamadas.svg'>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's generalize the backpropagation phase. Let's start with the gradient descent, which can be generalized as follows:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{ll} \n",
    "W^{(l)} = W^{(l)} - \\alpha\\nabla_{\\omega}^{(l)} \\\\\n",
    "\\vec{b}^{(l)} = \\vec{b}^{(l)} - \\vec{\\alpha \\nabla_{b}}^{(l)} \n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Let's calculate the divergences using index notation for the $i$-th neuron in layer $l$ that connects to the $j$-th neuron in layer $l+1$, thus we have:\n",
    "\n",
    "$$\\nabla_{b_j}^{(l)} = \\frac{\\partial C_x}{\\partial b^{(l)}_j} , ~~~~ \\nabla_{\\omega_{ij}}^{(l)}=\\frac{\\partial C_x}{\\partial \\omega^{(l)}_{ij}}$$\n",
    "\n",
    "And therefore, as done for 2 hidden layers, we generalize for multiple layers in index notation:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{ll} \n",
    "\\nabla_{\\omega_{ij}}^{(l)} =\\frac{\\partial C_x}{\\partial \\omega^{(l)}_{ij}}={\\frac{\\partial C_x}{\\partial{\\textrm{net}_j}^{(l)} }}{\\frac{\\partial{\\textrm{net}_j}^{(l)}}{\\partial {\\omega^{(l)}_{ij}}}}={\\delta^{(l+1)}_j} {z_{i}^{(l)}}\\\\\n",
    "\\\\\\nabla_{b_j}^{(l)} =\\frac{\\partial C_x}{\\partial b^{(l)}_{j}} ={\\frac{\\partial C_x}{\\partial{{\\textrm{net}_j}^{(l)}}}}\\frac{\\partial{{\\textrm{net}_j}^{(l)}}}{\\partial {b^{(l)}_{j}}}={\\delta^{(l+1)}_j}\\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Therefore, each neuron carries a $\\delta$ error used to optimize and update the network parameters through gradient descent. Let's now transform this index form into a matrix form, just like in the feedforward step. Consider a vector of errors that represents the errors related to each neuron in layer $l$ and the vector representing the neurons in that layer, respectively:\n",
    "\n",
    "$$\n",
    "\\vec{\\delta}^{(l)} =\n",
    "\\left( \\begin{array}{c}\n",
    "\\delta_{1}^{(l)}\\\\\n",
    "\\delta_{2}^{(l)}\\\\\n",
    "\\vdots\\\\\n",
    "\\delta_{n_l}^{(l)}\n",
    "\\end{array} \\right),~~~~\n",
    "\\vec{z}^{(l)} =\n",
    "\\left( \\begin{array}{c}\n",
    "z_{1}^{(l)}\\\\\n",
    "z_{2}^{(l)}\\\\\n",
    "\\vdots\\\\\n",
    "z_{n_l}^{(l)}\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "We can then write the divergences in matrix notation:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{ll} \n",
    "\\nabla_{W}^{(l)} =  {\\vec{z}^{(l)}}{\\vec{\\delta}^{(l+1)}}^T\\\\\n",
    "\\\\ \\vec{\\nabla_{b}}^{(l)} = {\\vec{\\delta}^{(l+1)}}\\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "There is a subtle difference between the errors of the neurons in the hidden layer and the output layer. Let's consider each case separately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I. Output Layer ($l = h+1$)**\n",
    "\n",
    "\n",
    "Consider using an activation function for the output that is not the softmax function. This is because when using the softmax function, the output neurons are no longer independent, and this changes the calculations, introducing a sum to compute such dependence. Calculating the error for the $j$-th neuron in layer $l=h+1$,\n",
    "\n",
    "$${\\delta^{(h+1)}_j =\\frac{\\partial C_x}{\\partial \\text{net}^{(h+1)}_j}} = \\frac{\\partial C_x}{\\partial O_j}\\frac{\\partial O_j}{\\partial{\\text{net}^{(h+1)}_j}},$$\n",
    "\n",
    "\n",
    "is done as we had done for a three-layer network. We can switch from index notation to matrix notation by simply transforming each derivative into a derivative vector. We will have a vector containing the derivatives of the cost function for each output neuron and a vector with the derivative of the output neuron with respect to its argument $net_j$. Remember that referring to the neuron is equivalent to referring to the activation function, since the neuron is fundamentally the activation function itself, that is, $O_j = \\sigma^{(h+1)}(net_j)$. We therefore have the following vectors:\n",
    "\n",
    "\n",
    "$$\n",
    "\\partial{\\vec{C_x}} =\n",
    "\\left( \\begin{array}{c}\n",
    "\\frac{\\partial C_x}{\\partial O_1}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial C_x}{\\partial O_j}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial C_x}{ \\partial O_{n_{(h+1)} }}\\\\\n",
    "\\end{array} \\right),~~~~\n",
    "\\partial{\\vec{o}} =\n",
    "\\left( \\begin{array}{c}\n",
    "\\frac{\\partial O_1}{\\partial{\\text{net}^{(h+1)}_1}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial O_j}{\\partial{\\text{net}^{(h+1)}_j}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial O_1}{\\partial{\\text{net}^{(h+1)}_{n_{(h+1)}}}}\n",
    "\\end{array} \\right).\n",
    "$$\n",
    "\n",
    "Rewriting the equation for the error of each neuron in its matrix form, we have:\n",
    "\n",
    "$$\\vec{\\delta}^{(h+1)} = \\partial{\\vec{C_x}} \\odot \\partial{\\vec{o}},$$\n",
    "\n",
    "where **$\\odot$ is called the Hadamard product, in which basically the rows of one vector will be multiplied by the corresponding rows of the other vector**. In the common inner product, we would have multiplication of rows by columns instead of rows by rows. The form of the error vector for neurons in the output layer is:\n",
    "\n",
    "$$\n",
    "\\vec{\\delta}^{(h+1)} =\n",
    "\\left( \\begin{array}{c}\n",
    "\\frac{\\partial C_x}{\\partial {O_1}} .\\frac{\\partial O_1}{\\partial{\\text{net}^{(h+1)}_1}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial C_x}{\\partial {O_j}}.\\frac{\\partial O_j}{\\partial{\\text{net}^{(h+1)}_j}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial C_x}{\\partial { O_{n_{(h+1)}} }}.\\frac{\\partial O_1}{\\partial{\\text{net}^{(h+1)}_{n_{(h+1)}}}}\n",
    "\\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II. Hidden layers ($l = h$ to $l = 1$)**\n",
    "\n",
    "We now need to calculate the errors propagated through the hidden layers down to the input layer. Let's consider again the result previously calculated for a three-layer network and generalize it here for multiple layers:\n",
    "\n",
    "$$\\delta^{(l)}_j=\\frac{\\partial C_x}{ \\partial{ \\text{net}_j^{(l)}} }= \\sum_{k=1}^{n_{(l+1)}}\\textcolor{green}{\\frac{\\partial C_x}{ \\partial{ \\text{net}_k^{(l+1)}}}}\\frac{\\partial \\text{net}_k^{(l)}}{\\partial{z_j^{(l)}}}\\frac{\\partial z_j^{(l)}}{\\partial{ net_j^{(l)}}}\\\\\n",
    "\\delta^{(l)}_j=\\frac{\\partial z_j^{(l)}}{\\partial{ net_j^{(l)}}} \\sum_{k=1}^{n_{(l+1)}}\\textcolor{green}{\\delta^{(l+1)}_k}\\omega_{jk}^{(l)}.$$\n",
    "\n",
    "Suppose we have already calculated the error $\\delta^{(l+1)}_j$ in layer $l+1$. This is because the neuron $z_j^{(l)}$ connects with all neurons in layer $l+1$, as shown explicitly in the equation above. Let's again consider a vector of derivatives of the neurons with respect to their arguments:\n",
    "\n",
    "$$\\partial{\\vec{z}^{(l)}} =\n",
    "\\left( \\begin{array}{c}\n",
    "\\frac{\\partial z^{(l)}_1}{\\partial{\\text{net}^{l}_1}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial z_j^{(l)}}{\\partial{\\text{net}^{l}_j}}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial z_{n_l}^{(l)}}{\\partial{\\text{net}^{(l)}_{n_{l}}}}\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "We have an iterative equation for $l \\in [1 ,h]$, where the value of the error $\\vec{\\delta}^{(l)}$ depends on the calculation of the error $\\vec{\\delta}^{(l+1)}$ in the previous layer in the backpropagation phase, as we can see:\n",
    "\n",
    "$$\\vec{\\delta}^{(l)}= \\partial{\\vec{z}^{(l)}} \\odot \\left( W^{(l)}. \\vec{\\delta}^{(l+1)} \\right)$$\n",
    "\n",
    "Therefore, in the backpropagation phase, we have:\n",
    "\n",
    "$$\n",
    "\\vec{\\delta}^{(l)}=\\left\\{ \\begin{array}{ll} \n",
    "\\partial{\\vec{o}}\\odot \\partial{\\vec{C_x}}  &\\text{se}~~~~~~~~l = h+1\\\\\n",
    "\\partial{\\vec{z}^{(l)}} \\odot \\left( W^{(l)}. \\vec{\\delta}^{(l+1)} \\right)~~~~~~~~~~ &\\text{se}~~~~~~~~l \\in [1,h]\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0743c798041383927c03f3bae5eca888e94e4777f716cdd511cdff96fbdedc02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
